{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Image Classification Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M32895 Course Work \"Big Data\" 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook objectives\n",
    "* Build, train and test a convolutional neural network (CNN) for Classification task using an image dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes and comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # tf will show error messages only (reduce verbosity)\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Load data</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(X_train.shape, X_test.shape)\n",
    "# The dataset is already preprocessed and split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(np.unique(y_train))\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Workflow for data acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the data first. We are using the fashion_mnist dataset from tensorflow. It has 28x28 graiscale images of clothes and we are interested in predicting which piece of close it is.\n",
    "* The data are split into train and test sets (It is available from TensorFlow in this format).\n",
    "* This is a demo dataset, where all images are provided in a single and standardized format and arranged in a NumPy array.\n",
    "* This is useful for learning purposes. However, actual image datasets rarely have the characteristic of having all images of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = 15 # number of image in the dataset (remember, numbering starts from 0!)\n",
    "\n",
    "print(f\"array pointer = {pointer}\")\n",
    "print(f\"x_train[{pointer}] shape: {X_train[pointer].shape}\")\n",
    "print(f\"label: {y_train[pointer]}\")\n",
    "\n",
    "plt.imshow(X_train[pointer],cmap='Accent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fashion MNIST dataset labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fashion MNIST dataset labels](../assets/img/fashion_mnist_labels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Data preparation</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fashion MNIST dataset is already loaded as a NumPy array, there's no need to check file extensions like we **would do** for actual image files. However, we can still verify whether all elements in X_train, X_test, and Y_train are valid image data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clean data.\n",
    "    * Steps to Validate Images in Fashion MNIST\n",
    "        * Check the data type → Images should be numeric arrays (uint8 type).\n",
    "        * Check the shape of each image → All images should be 28×28 pixels.\n",
    "        * Check for corrupted images (e.g., containing NaN values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_images(dataset, dataset_name):\n",
    "    \"\"\"\n",
    "    Checks images for:\n",
    "    * being an array\n",
    "    * shape (28x28)\n",
    "    * colour channel values\n",
    "    * NaN values\n",
    "    \"\"\"\n",
    "    invalid_count = 0  # Counter for invalid images\n",
    "    valid_count = 0     # Counter for valid images\n",
    "\n",
    "    for idx, image in enumerate(dataset):\n",
    "        # Check if the image is a NumPy array\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            print(f\"{dataset_name} - Index {idx}: Not a valid image array\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        # Check shape (should be 28x28)\n",
    "        if image.shape != (28, 28):\n",
    "            print(f\"{dataset_name} - Index {idx}: Incorrect shape {image.shape}\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        # Check if values are within expected range (0-255 for grayscale images)\n",
    "        if not (image.dtype == np.uint8 and image.min() >= 0 and image.max() <= 255):\n",
    "            print(f\"{dataset_name} - Index {idx}: Invalid pixel values (Min: {image.min()}, Max: {image.max()})\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        # Check for NaN values\n",
    "        if np.isnan(image).any():\n",
    "            print(f\"{dataset_name} - Index {idx}: Contains NaN values\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        valid_count += 1\n",
    "\n",
    "    print(f\"\\n{dataset_name}: {valid_count} valid images, {invalid_count} invalid images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run checks on both datasets\n",
    "print(\"Checking Images...\\n\")\n",
    "check_images(X_train, \"Train\")\n",
    "check_images(X_test, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Further data splitting: from the **train** set, we split a **validation** set. We set the validation set as 20% of the train set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                    X_train,\n",
    "                                    y_train,\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0\n",
    "                                    )\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"* Validation set:\",  X_val.shape, y_val.shape)\n",
    "print(\"* Test set:\",   X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>EDA</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot label frequency distribution in train, validation and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names. Fasion MNIST has 10 labels\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for label frequency distribution\n",
    "df_freq = pd.DataFrame(columns=['Set', 'Label', 'Frequency'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(dataset, dataset_name):\n",
    "    \"\"\"\n",
    "    Helper function to count occurrences of each label and print them\n",
    "    \"\"\"\n",
    "    global df_freq\n",
    "    unique, counts = np.unique(dataset, return_counts=True)  # Get label frequencies\n",
    "    for label, frequency in zip(unique, counts):\n",
    "        df_freq = pd.concat([df_freq, pd.DataFrame([{'Set': dataset_name, 'Label': class_names[label], 'Frequency': frequency}])], ignore_index=True)\n",
    "        print(f\"* {dataset_name} - {class_names[label]}: {frequency} images\")  # Print formatted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_labels(y_train, \"Train\")\n",
    "count_labels(y_test, \"Test\")\n",
    "count_labels(y_val, \"Validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the label distribution and save image\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Label Frequency Distribution in Train, Validation, and Test Sets\")\n",
    "plt.savefig(\"/workspaces/m32895-coursework-2025/outputs/label_distribution_in_sets.png\", bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we can ask ourselves:\n",
    "* Is the dataset <u>balanced</u>?\n",
    "* Do we have enough data?\n",
    "* Are we going to run **augmentation**?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * We need to **reshape** and **rescale** the data to make it digestible by Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current data shape:\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When using Convolutional Neural Networks (CNNs), the Fashion MNIST dataset needs to be reshaped to include a \"channel\" dimension because CNNs typically expect 4D input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Dataset Type | Required Shape for CNN |\n",
    "|--------------|------------------------|\n",
    "| Grayscale Images (e.g. Fashion MNIST) | (num_images, height, width, 1) |\n",
    "| RGB Images | (num_images, height, width, 3) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.b.: we are taking these steps for scaling the data and reshaping to include the channel dimension since the data was provided in such format and is in a NumPy array format\n",
    "\n",
    "When you get image datasets in a NumPy format, you will recheck these items, and if required, you will need to process them.\n",
    "However, when dealing with real images, the preprocessing tasks are done in another way, which we will cover in the walkthrough of project 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape Fashion MNIST data for CNN\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "# Check the new shape\n",
    "print(X_train.shape)  # Expected output: (48000, 28, 28, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Convert to **float** and reshape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_val = X_val.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What Happens After Scaling?\n",
    "\n",
    "| Before Scaling (uint8) | After Scaling (float32) |\n",
    "|---|---|\n",
    "| Pixel values: 0 - 255 | Pixel values: 0.0 - 1.0 |\n",
    "| Integer type (uint8) | Floating-point (float32)|\n",
    "| Can cause instability in training | Helps stable and faster training |\n",
    "* The model learns better and converges faster when inputs are scaled to [0,1].\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Convert labels to categorical format**\n",
    "n_labels = 10  # Fashion MNIST has 10 classes\n",
    "y_train = to_categorical(y_train, num_classes=n_labels)\n",
    "y_val = to_categorical(y_val, num_classes=n_labels)\n",
    "y_test = to_categorical(y_test, num_classes=n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Building our model</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Finally! We are about to create a TensorFlow model\n",
    "\n",
    "* We create a function that\n",
    "    * creates a sequential model\n",
    "    * compiles the model\n",
    "    * returns the model\n",
    "    \n",
    "* The function needs the input shape (image size) as well as the number of neurons in the last layer\n",
    "* The network has two pairs of Convolution + Pooling layers. It is know upfront that for this dataset that one pair would be enough; however, we want to try in this work different combination of layers and their parameters for educational purposes.\n",
    "* <u>Brief summary</u> (refer to previous tutorials for more details):\n",
    "    * **Convolution layers** are used to select the dominant pixel value from within images using filters\n",
    "    * **Pooling layers** reduce the image size by extracting only the dominant pixels\n",
    "* The first pair has a convolution layer with 16 filters and a kernel size of 3x3.\n",
    "* We parse the input shape as well as the **relu** as an activation function.\n",
    "* The **MaxPool** has a pool size of 2x2\n",
    "* The next pair has the same setup as the previous pair\n",
    "* Next, there is a Flatten layer\n",
    "    * The Flatten layer is used to flatten the matrix into a vector, which means a single list of all values. Then that is fed into a dense layer.\n",
    "* Next, there is a Dense layer with 128 neurons.\n",
    "\n",
    "\n",
    "* Typically, here, you arrange the dense layers in multiples of 2, and the number of layers depends on the data complexity after the Flatten layer.\n",
    "* We will check in the `.summary()` or `.plot_model()` that the data shape after the Flatten layer is 400, so it makes sense to reduce the number of neurons from this case, 400 to 128. So naturally, you will only know the output from the Flatten layer is 400 after creating a model and checking the summary/plot_model.\n",
    "If the output from the Flatten layer were much higher, like 5k, you would consider two or more dense layers to reduce the number of connections progressively.\n",
    "* The value 128 is a good starting point. If you notice the CNN is not learning, you may add more dense layers and adjust the number of neurons in them\n",
    "* After, we have a dropout layer with a rate of 25% to reduce the chance of overfitting.\n",
    "* **The output layer should reflect a multiclass classification.**\n",
    "* We set a dense layer where the number of neurons equals the number of classes in the target variable. This information is stored in a previously created variable - `n_labels`.\n",
    "* For multiclass classification, we set the activation function as softmax, and we compile the model with adam as the optimizer and the loss function as categorical_crossentropy.\n",
    "* We also arranged to monitor the metric accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_model(input_shape, n_labels):\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Conv2D(filters=16, kernel_size=(3,3),input_shape=input_shape, activation='relu',))\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Conv2D(filters=16, kernel_size=(3,3), activation='relu',))\n",
    "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "\n",
    "  model.add(Flatten())\n",
    "\n",
    "  model.add(Dense(128, activation='relu'))\n",
    "  model.add(Dropout(0.25))\n",
    "\n",
    "  model.add(Dense(n_labels, activation='softmax'))\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_tf_model(input_shape=X_train.shape[1:], n_labels=n_labels )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Fit the model</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Early stopping allows us to stop the training when a monitored metric has stopped improving\n",
    "    * This is useful to avoid **overfitting** the model to the data.\n",
    "\n",
    "* We will monitor the validation accuracy now\n",
    "    * We set patience as 1, the number of epochs with no improvement, after which training will be stopped\n",
    "    * There is no fixed rule to set patience\n",
    "    * If you feel that your model is learning still and you stopped, you may increase the value and train again\n",
    "    * However, we want the training process to be quick, (for demo purpose, n/a in your course work)\n",
    "    * We set the mode to min since now we want the model to stop training when the loss didn't improve its performance and improve means decrease\n",
    "* We will finally fit the model\n",
    "    * We create the model object and use `.fit()`\n",
    "    * We parse the Train set\n",
    "    * The epochs are set to 4. We know in advance that this amount is fine to learn the patterns considering the dataset and the network structure\n",
    "    * We parse the validation data in a tuple\n",
    "    * Verbose is set to 1, so we can see in which epochs we are and the training and validation loss\n",
    "    * Finally, we parse our callback as the early_stop object we created earlier\n",
    "* For each epoch, note the training and validation loss and accuracy. Is it increasing? Decreasing? Static?\n",
    "* Ideally, the loss should decrease as long as the epoch increases, showing a practical sign the network is learning. The accuracy should increase over the epochs.\n",
    "* Note the model will take a bit longer now to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_tf_model(input_shape= X_train.shape[1:], n_labels=n_labels )\n",
    "\n",
    "model.fit(x=X_train,\n",
    "          y=y_train,\n",
    "          epochs=4,\n",
    "          validation_data=(X_val, y_val),\n",
    "          verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Model evaluation</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluate the model performance by analysing the training and the validation losses and accuracy that happened during the training process\n",
    "* In deep learning, we use the model history to assess if the model learned, using the train and validation sets\n",
    "* We also evaluate separately how the model **generalises** on unseen data (on the test set)\n",
    "* The model training history information is stored in a .history.history attribute from the model\n",
    "* Note it shows loss and accuracy for train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DataFrame(model.history.history)\n",
    "history.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "history[['loss','val_loss']].plot(style='.-')\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "history[['accuracy','val_accuracy']].plot(style='.-')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will evaluate the model performance on the test set, using `.evaluate()` and parsing the test set\n",
    "* N.b. the value is not much different from the losses and accuracy in the train and validation set\n",
    "* N.b. the loss is low and accuracy is high. It looks like the model has learned the relationships between the features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In classification, you would analyse the confusion matrix and classification report using the custom function we have seen over the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_and_report(X,y,pipeline,label_map):\n",
    "  \"\"\"\n",
    "  Print confusion matrix and report\n",
    "  \"\"\"\n",
    "  # the prediction comes in a one hot encoded format\n",
    "  prediction = pipeline.predict(X)\n",
    "  # so we take the index from the highest probability, which is the \"winner\" or predicted class\n",
    "  prediction = np.argmax(prediction, axis=1)\n",
    "\n",
    "  # we also take the index from the highest probability from the actual values\n",
    "  y = np.argmax(y, axis=1)\n",
    "\n",
    "  print('---  Confusion Matrix  ---')\n",
    "  print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
    "        columns=[ [\"Actual \" + sub for sub in label_map] ],\n",
    "        index= [ [\"Prediction \" + sub for sub in label_map ]]\n",
    "        ))\n",
    "  print(\"\\n\")\n",
    "\n",
    "  print('---  Classification Report  ---')\n",
    "  print(classification_report(y, prediction, target_names=label_map),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_performance(X_train,y_train,X_test,y_test,X_val, y_val,pipeline,label_map):\n",
    "  \"\"\"\n",
    "  Print classification performance\n",
    "  \"\"\"\n",
    "  print(\"#### Train Set #### \\n\")\n",
    "  confusion_matrix_and_report(X_train,y_train,pipeline,label_map)\n",
    "\n",
    "  print(\"#### Validation Set #### \\n\")\n",
    "  confusion_matrix_and_report(X_val,y_val,pipeline,label_map)\n",
    "\n",
    "  print(\"#### Test Set ####\\n\")\n",
    "  confusion_matrix_and_report(X_test,y_test,pipeline,label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_performance(X_train, y_train,\n",
    "                X_test,y_test,\n",
    "                X_val, y_val,\n",
    "                model,\n",
    "                label_map= class_names\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <u>Prediction</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's take a sample from the test set and use it as if it was live data. We will consider 1 sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 102\n",
    "my_garment = X_test[index]\n",
    "class_index = np.argmax(y_test[index])\n",
    "print(my_garment.shape)\n",
    "print(y_test[index])\n",
    "print(f\"This is '{class_names[class_index]}'\")\n",
    "\n",
    "sns.set_style('white')\n",
    "plt.imshow(my_garment.reshape(28,28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_garment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* However when interacting with the **model**, we need the data in 4 dimensions, where the first dimension is the number of images the data has, the next 2 are the image size and the last is the color channels\n",
    "* In our case, we need to add the first dimension, and the value will be 1, so the final shape is (1 ,28 ,28 ,1 )\n",
    "* We use the command  `np.expand_dims()` for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_data = np.expand_dims(my_garment, axis=0)\n",
    "print(live_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We use `.predict()` and parse the data\n",
    "* N.b. the result is a *probabilistic* result for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_proba = model.predict(live_data)\n",
    "prediction_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* So we take the index from the highest probability, which is the \"winner\" or predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_class = np.argmax(prediction_proba, axis=1)\n",
    "prediction_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot the probabilistic result so that you can check the predictions in a more visual fashion\n",
    "* Read the pseudo-code\n",
    "* In the end you are getting prediction_proba to define the associate probability for each class\n",
    "* Then you plot it in a bar plot using Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe, that will show the probability per class\n",
    "# we set the probabilities as the prediction_proba\n",
    "prob_per_class= pd.DataFrame(data=prediction_proba[0],\n",
    "                             columns=['Probability']\n",
    "                             )\n",
    "\n",
    "# we round the values to 3 decimal points, for better visualization\n",
    "prob_per_class = prob_per_class.round(3)\n",
    "\n",
    "# we add a column to prob_per_class that shows the meaning of each class\n",
    "# in this case, the species name that is mapped in the target_classes\n",
    "prob_per_class['Results'] = class_names\n",
    "\n",
    "prob_per_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot prediction probability for each garment in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "        prob_per_class,\n",
    "        x = 'Results',\n",
    "        y = 'Probability',\n",
    "        range_y=[0,1],\n",
    "        width=600, height=400,template='seaborn')\n",
    "fig.update_xaxes(type='category')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
